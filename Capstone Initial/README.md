# Retail Revenue Prediction based on Multi Channels Consumer Sale


## 1) Executive Summary


### 1.1) Project Overview

In the retail industry, a key component for successful marketing team is to identify consumer behavior to enhance consumer Acquisition and retention, detecting people who are using multiple ways for buying products and based on behavior offering different channels may be based on age-group, gender preferences, demographic and many more factors effecting consumer preferences in this age of social media posts. 

This project is to identify effective consumer channels and payment methods to enhance revenue growth and prediction of a retail business revenue streams, offering multi sales channels to consumers for buying products form the retail, which includes, 
<br> - over e-commerce website, 
<br> - thru iOS mobile app, 
<br> - thru Android mobile app, 
<br> - from marketplace like Amazon.
 
### 1.2) Project Objective Question

The question this project aims to answer is what is the best model for predicting retail sales for revenue stream generated by channels. We will be looking at the dataset from the perspective of a retail marketing analyst who will be looking to answer the following questions:
<br> - Can revenue stream be predicted for retail based on prior channels performance?
<br> - What are the key features that drive the retail revenue predictions?

### 1.3) Findings

We will be training and tuning four models to accurately address the questions on behalf of marketing analyst. We will then evaluate and compare the four models' performances to identify the best one, then further scrutinize it to find the most effective features that enhance performance in this task. 

### 1.4) Results and Conclusion

We will draw insights from this model by conducting an analysis based on dataset, using libraries, identify the most important words/features used for making accurate predictions. We will also be locally analyzing this model and evaluating its class prediction process. Lastly, we will draw insights from our analyses and recommend areas to research and courses to undertake for future work in enhancing retail revenue stream, consumer preferences related to different channels and payment methods and regional effects.


## 2) Rationale

**Business Objective:** The marketing team wants to predict how much revenue will be generated by different channels, payment methods and regions. If the team can predict the revenue generated by features, they will be able to optimize their spending advertising budget on different channels and regions to maximize profit. 

By utilizing such analysis and predictive modeling, retail enterprises can focus on key revenue stream in form of channels, regions and plan their marketing campaigns and promotional activities for more customer acquisitions and retention. This would also help down the line to provide more accurate revenue guidance at enterprise level and mitigate multiple financial risks.


## 3) Understanding the Data

### 3.1) Data Source

This data is collected from Retail e-commerce enterprise by random sampling of transactions over different channels between CY'2021 to CY'2023.

More than 50K random samples from the data is used for model training to facilitate computation.

### 3.2) Data Problem Definition

We will be using this dataset to build a model that can predict the revenue generated by retail channels. We will also be looking at the features that drive the predictions of the model to provide insight to the marketing team.

### 3.3) Data Description & Basic Analysis

The dataset contains the following columns:
- **date**: The date of the record.
- **channel**: channel identifier.
- **network_payment_hash**: A hashed representation of the network payment.
- **region**: Geographical region.
- **days_after_registration**: Days passed since the user installed the app or register.
- **period**: Time period (in this case, it appears to be 'day' for all rows).
- **network_payment**: Name of the network payment method.
- **spend**: Amount spent.
- **cohort_size**: Size of the cohort.
- **organic_cohort_size**: Size of the organic cohort.
- **retained_users**: Number of users retained.
- **organic_retained_users**: Number of organic users retained.
- **revenue_ad**: Revenue from ads.
- **revenue_iap**: Revenue from in-app purchases.
- **revenue_sub**: Revenue from subscriptions.
- **organic_revenue_ad**: Organic revenue from ads.
- **organic_revenue_iap**: Organic revenue from in-app purchases.
- **organic_revenue_sub**: Organic revenue from subscriptions.

### 3.4) Exploratory Data Analysis

Finding out dstriution of different features in the data using visual plots

<img src="images/distriution1" width="100%">

**Observation:** From the above statistics and plots, we see that:
<br>- Many columns have a mean that's much higher than the median. This suggests that the data is skewed, with a few large values pulling the mean up.
<br>- Many metrics have a median of zero, indicating that for at least half of the records, there was no spend, revenue, or user retention.
<br> - The majority of records have a spend close to zero, and there's a long tail with a few records having significantly higher spends.
<br> - Most records have a smaller cohort size, but there are outliers with larger sizes.
<br> - A similar pattern to the cohort size, with the majority of records having smaller organic cohort sizes.
<br> - The majority of records have a low number of retained users, with a few having a significantly higher count.
<br> - Most records have revenue close to $0, with a long tail representing a few records with higher revenues.
<br> - A similar pattern to the revenue from ads.
<br> - Most records have no subscription revenue, with a few exceptions.

### 3.5) Preprocessing

### 3.5 (a) Preprocessing transformation

Preprocessing dataset to make it ready for modeling, this includes some cleanups or adding few additional columns transforming data into the required form.

The initial dataset doesn't have a total_revenue and total_organic_revenue columns. Added these two column in the dataset for model and evaluation purpose.

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 51405 entries, 0 to 51404
Data columns (total 20 columns):
 **Column**                   Non-Null Count  Dtype  
---  ------                   --------------  -----  
 0   date                     51405 non-null  object 
 1   channel                  51405 non-null  object 
 2   network_payment_hash     51405 non-null  int64  
 3   region                   51405 non-null  object 
 4   days_after_registration  51405 non-null  int64  
 5   period                   51405 non-null  object 
 6   network_payment          51405 non-null  object 
 7   spend                    51405 non-null  float64
 8   cohort_size              51405 non-null  int64  
 9   organic_cohort_size      51405 non-null  float64
 10  retained_users           51405 non-null  int64  
 11  organic_retained_users   51405 non-null  float64
 12  revenue_ad               51405 non-null  float64
 13  revenue_iap              51405 non-null  float64
 14  revenue_sub              51405 non-null  float64
 15  organic_revenue_ad       51405 non-null  float64
 16  organic_revenue_iap      51405 non-null  float64
 17  organic_revenue_sub      51405 non-null  float64
 18  total_revenue            51405 non-null  float64
 19  total_organic_revenue    51405 non-null  float64
dtypes: float64(11), int64(4), object(5)

### 3.5 (b) Multivariate plots

Plotted multivariate plots to get more insights into the coreralation before final dataset preparation

<img src="images/multi1" width="100%">

<img src="images/multi2" width="100%">

**Observations:**

- **Spend vs Total Revenue (by Region)**: There tends to be more spend (and revenue) on NorthAm,LatAm regions vs other regions.
- **Cohort Size vs Retained Users**: There are some interesting patterns here than need further investigation.
- **Spend by region** China is top3 in spend, APAC doesn't get much spend - that's interesting.
- **Total Revenue by Region**: NorthAm and LatAm at the top of the list - makes sense.
- **Spend vs Total Revenue (by channel)**: No clear pattern here, needs more investigation.
- **Days After Registration vs Total Revenue**: revenue drops over time.
- **Spend vs Total Revenue (by Channel)**: I don't see very clear pattern here.
- **Cohort Size vs Retained Users (by days after registration)**: The days_after_registration dimension needs some work to actually be useful.
- **Spend by Channel** Aside from "Marketplace" the rest of the apps get very similar spend budgets.
- **Total Revenue by Channel**: "Marketplace" gives pretty good returns since the gap in revenue closed significantly (vs spend).
- **Spend vs Total Revenue (by region)**: We can see the same region specific trends.
- **Days After Registration vs Total Revenue**: The NorthAm region clearly outperforms the other ones.

### 3.5 (c) Group Based Analysis

Grouping data by 'cahnnel wise' and 'network_payment' for calculating the mean for selected metrics

<img src="images/grp1" width="100%">

<img src="images/grp2" width="100%">

**Observation:** 

"PayPal" outperforms the other ones especially when it comes to retained users. That's probably the reason why it gets a bigger spend budget.

"Android Apps" comes at the top but its iOS counterpart is quite close - important callout is although the android app gets less spend budget. "Website" retains much better than the rest although it doesn't monetize as good as the others.


## 4) Methodology & Data Preparation

Models bee trained on the training set and validated with the test set. To be used to evaluate models using accuracy score, and fine tuned each model's parameters to maximize this metric.  Accuracy is suitable because we have a balanced dataset and measures the proportion of correctly predicted observations out of total observations. 

### 4.1) Train vs Test Set

Preparing the data to make it ready for modeling and deployment including spliting it into train set and test set with test size of 0.2 (20% test set)

### 4.2) Model Training

Four models were trained, fine-tuned, and be later compared to find the best model for this task.

**- Linear regression model** 

**- DecisionTreeRegressor** 

**- RandomForestRegressor** 

**- GradientBoostingRegressor**


## 5) Model Evaluation and Results 

**Performance Metrics:**
- **Mean Squared Error (MSE):** \(12794.72\)
  - This metric represents the average squared difference between the predicted values and the actual values. A lower MSE indicates a better fit of the model to the data. In this case, the MSE of \(12794.72\) indicates the magnitude of the error made by the model in its predictions.
  
- **\( R^2 \) Score:** \(0.3375\)
  - The \( R^2 \) score, also known as the coefficient of determination, measures the proportion of the variance in the dependent variable that is predictable from the independent variables. An \( R^2 \) score of \(0.3375\) suggests that the model explains about 33.75% of the variance in the target variable. This is a low \( R^2 \) value, which means the model captures very little of the underlying structure of the data and needs improvement.

**Feature Coefficients:**

The coefficients represent the change in the dependent variable (in this case, `total_revenue`) for a one-unit change in the predictor variable, while holding all other predictors constant.

1. **Regions (NorthAM, EMEA, APAC, LatAM):** 
   - `region_NorthAM` has the highest positive coefficient of \(12.639\), suggesting that being in this region is associated with a significant increase in `total_revenue`. The other regions (`region_EMEA`, `region_APAC`, `region_LatAM`) also have positive coefficients, but with decreasing magnitude. This implies a hierarchy in terms of contribution to `total_revenue`, with `region_NorthAM` being the most influential.
  
2. **Retention Columns:**
   - `organic_retained_users` has a positive coefficient of \(0.7805\), which means for every additional user retained organically, the `total_revenue` increases by approximately \(0.78\). 
   - `retained_users` has a coefficient of \(0.1252\), indicating a smaller positive impact on `total_revenue` compared to organic retained users.
   
3. **Networks:**
   - The coefficient for `network_paymeent_PayPal` is \(0.0149\), implying a slight increase in `total_revenue` associated with this network.
   - `network_payment_MobilePay` has a negative coefficient, suggesting a decrease in `total_revenue` for this channel compared to the reference network.
<br>
   
4. **Spend:** A coefficient of \(0.0057\) indicates that for every unit increase in spend, there's a small positive effect on `total_revenue`.

5. **Cohort Sizes:** 
   - The negative coefficient for `cohort_size` (-0.0023) suggests a very slight decrease in `total_revenue` for every unit increase in the cohort size.
   - The negative coefficient for `organic_cohort_size` is larger in magnitude (-0.0215), implying a more noticeable negative effect on `total_revenue`.

6. **Channels:**
   - All channels (`iOS App`, `Website`, `Marketplace`) have negative coefficients, suggesting they negatively impact `total_revenue`. Among them, `Marketplace` has the largest negative coefficient, indicating it has the most significant negative impact on `total_revenue` compared to the reference channel.


### Results
- The model moderately fits the data, capturing around 33.75% of the variance in `total_revenue`.
- Regions play a significant role in predicting `total_revenue`, with `region_NorthAM` having the most substantial positive impact.
- Retention of organic users is more influential than general user retention in terms of increasing `total_revenue`.
- Among the channels, `Marketplace` has the highest negative impact on the revenue, suggesting potential areas for business improvement.
- While spend has a positive impact on `total_revenue`, the effect of cohort sizes is slightly negative, implying that other factors, such as user quality, might play a more crucial role than sheer numbers.

Thank You!