# Retail Revenue Prediction based on Multi Channels Consumer Sale


## 1) Executive Summary


### 1.1) Project Overview

In the retail industry, a key component for successful marketing team is to identify consumer behavior to enhance consumer Acquisition and retention, detecting people who are using multiple ways for buying products and based on behavior offering different channels may be based on age-group, gender preferences, demographic and many more factors effecting consumer preferences in this age of social media posts. 

This project is to identify effective consumer channels and payment methods to enhance revenue growth and prediction of a retail business revenue streams, offering multi sales channels to consumers for buying products form the retail, which includes, 
<br> - over e-commerce website, 
<br> - thru iOS mobile app, 
<br> - thru Android mobile app, 
<br> - from marketplace like Amazon.
 
### 1.2) Project Objective Question

The question this project aims to answer is what is the best model for predicting retail sales for revenue stream generated by channels. We will be looking at the dataset from the perspective of a retail marketing analyst who will be looking to answer the following questions:
<br> - Can revenue stream be predicted for retail based on prior channels performance?
<br> - What are the key features that drive the retail revenue predictions?

### 1.3) Findings

We will be training and tuning four models to accurately address the questions on behalf of marketing analyst. We will then evaluate and compare the four models' performances to identify the best one, then further scrutinize it to find the most effective features that enhance performance in this task. 

### 1.4) Results and Conclusion

We will draw insights from this model by conducting an analysis based on dataset, using libraries, identify the most important words/features used for making accurate predictions. We will also be locally analyzing this model and evaluating its class prediction process. Lastly, we will draw insights from our analyses and recommend areas to research and courses to undertake for future work in enhancing retail revenue stream, consumer preferences related to different channels and payment methods and regional effects.

Here is link of my Jupyter notebook with all details together with analysis, coding evaluation, findings and conclusiuon.

[Jupyter Notebook](https://github.com/pbsus23/berkeley-pcert-ai-ml/tree/main/CapstoneFinal/prompt_final.ipynb)


## 2) Rationale

**Business Objective:** The marketing team wants to predict how much revenue will be generated by different channels, payment methods and regions. If the team can predict the revenue generated by features, they will be able to optimize their spending advertising budget on different channels and regions to maximize profit. 

By utilizing such analysis and predictive modeling, retail enterprises can focus on key revenue stream in form of channels, regions and plan their marketing campaigns and promotional activities for more customer acquisitions and retention. This would also help down the line to provide more accurate revenue guidance at enterprise level and mitigate multiple financial risks.


## 3) Understanding the Data

### 3.1) Data Source

This data is collected from Retail e-commerce enterprise by random sampling of transactions over different channels between CY'2021 to CY'2023.

More than 50K random samples from the data is used for model training to facilitate computation.

### 3.2) Data Problem Definition

We will be using this dataset to build a model that can predict the revenue generated by retail channels. We will also be looking at the features that drive the predictions of the model to provide insight to the marketing team.

### 3.3) Data Description & Basic Analysis

The dataset contains the following columns:
- **date**: The date of the record.
- **channel**: channel identifier.
- **network_payment_hash**: A hashed representation of the network payment.
- **region**: Geographical region.
- **days_after_registration**: Days passed since the user installed the app or register.
- **period**: Time period (in this case, it appears to be 'day' for all rows).
- **network_payment**: Name of the network payment method.
- **spend**: Amount spent.
- **cohort_size**: Size of the cohort.
- **organic_cohort_size**: Size of the organic cohort.
- **retained_users**: Number of users retained.
- **organic_retained_users**: Number of organic users retained.
- **revenue_ad**: Revenue from ads.
- **revenue_iap**: Revenue from in-app purchases.
- **revenue_sub**: Revenue from subscriptions.
- **organic_revenue_ad**: Organic revenue from ads.
- **organic_revenue_iap**: Organic revenue from in-app purchases.
- **organic_revenue_sub**: Organic revenue from subscriptions.

### 3.4) Exploratory Data Analysis

Finding out dstriution of different features in the data using visual plots

<img src="images/distriution1.png" width="100%">

**Observation:** From the above statistics and plots, we see that:
<br>- Many columns have a mean that's much higher than the median. This suggests that the data is skewed, with a few large values pulling the mean up.
<br>- Many metrics have a median of zero, indicating that for at least half of the records, there was no spend, revenue, or user retention.
<br> - The majority of records have a spend close to zero, and there's a long tail with a few records having significantly higher spends.
<br> - Most records have a smaller cohort size, but there are outliers with larger sizes.
<br> - A similar pattern to the cohort size, with the majority of records having smaller organic cohort sizes.
<br> - The majority of records have a low number of retained users, with a few having a significantly higher count.
<br> - Most records have revenue close to $0, with a long tail representing a few records with higher revenues.
<br> - A similar pattern to the revenue from ads.
<br> - Most records have no subscription revenue, with a few exceptions.

### 3.5) Preprocessing

### 3.5 (a) Preprocessing transformation

Preprocessing dataset to make it ready for modeling, this includes some cleanups or adding few additional columns transforming data into the required form.

The initial dataset doesn't have a total_revenue and total_organic_revenue columns. Added these two column in the dataset for model and evaluation purpose.

<img src="images/NewColumns.png" width="100%">

### 3.5 (b) Multivariate plots

Plotted multivariate plots to get more insights into the coreralation before final dataset preparation

<img src="images/multi1.png" width="100%">

<img src="images/multi2.png" width="100%">

**Observations:**

- **Spend vs Total Revenue (by Region)**: There tends to be more spend (and revenue) on NorthAm,LatAm regions vs other regions.
- **Cohort Size vs Retained Users**: There are some interesting patterns here than need further investigation.
- **Spend by region** China is top3 in spend, APAC doesn't get much spend - that's interesting.
- **Total Revenue by Region**: NorthAm and LatAm at the top of the list - makes sense.
- **Spend vs Total Revenue (by channel)**: No clear pattern here, needs more investigation.
- **Days After Registration vs Total Revenue**: revenue drops over time.
- **Spend vs Total Revenue (by Channel)**: I don't see very clear pattern here.
- **Cohort Size vs Retained Users (by days after registration)**: The days_after_registration dimension needs some work to actually be useful.
- **Spend by Channel** Aside from "Marketplace" the rest of the apps get very similar spend budgets.
- **Total Revenue by Channel**: "Marketplace" gives pretty good returns since the gap in revenue closed significantly (vs spend).
- **Spend vs Total Revenue (by region)**: We can see the same region specific trends.
- **Days After Registration vs Total Revenue**: The NorthAm region clearly outperforms the other ones.

### 3.5 (c) Group Based Analysis

Grouping data by 'cahnnel wise' and 'network_payment' for calculating the mean for selected metrics

<img src="images/grp1.png" width="100%">

<img src="images/grp2.png" width="100%">

**Observation:** 

"PayPal" outperforms the other ones especially when it comes to retained users. That's probably the reason why it gets a bigger spend budget.

"Android Apps" comes at the top but its iOS counterpart is quite close - important callout is although the android app gets less spend budget. "Website" retains much better than the rest although it doesn't monetize as good as the others.


## 4) Methodology & Data Preparation

Models bee trained on the training set and validated with the test set. To be used to evaluate models using accuracy score, and fine tuned each model's parameters to maximize this metric.  Accuracy is suitable because we have a balanced dataset and measures the proportion of correctly predicted observations out of total observations. 

### 4.1) Train vs Test Set

Preparing the data to make it ready for modeling and deployment including spliting it into train set and test set with test size of 0.2 (20% test set)

### 4.2) Model Training

Four models were trained, fine-tuned, and be later compared to find the best model for this task.

**- Linear regression model** 

**- DecisionTreeRegressor** 

**- RandomForestRegressor** 

**- GradientBoostingRegressor**


## 5) Model Evaluation and Results 

**Performance Metrics:**
- **Mean Squared Error (MSE):** \(12794.72\)
  - This metric represents the average squared difference between the predicted values and the actual values. A lower MSE indicates a better fit of the model to the data. In this case, the MSE of \(12794.72\) indicates the magnitude of the error made by the model in its predictions.
  
- **\( R^2 \) Score:** \(0.3375\)
  - The \( R^2 \) score, also known as the coefficient of determination, measures the proportion of the variance in the dependent variable that is predictable from the independent variables. An \( R^2 \) score of \(0.3375\) suggests that the model explains about 33.75% of the variance in the target variable. This is a low \( R^2 \) value, which means the model captures very little of the underlying structure of the data and needs improvement.

**Feature Coefficients:**

The coefficients represent the change in the dependent variable (in this case, `total_revenue`) for a one-unit change in the predictor variable, while holding all other predictors constant.

1. **Regions (NorthAM, EMEA, APAC, LatAM):** 
   - `region_NorthAM` has the highest positive coefficient of \(12.639\), suggesting that being in this region is associated with a significant increase in `total_revenue`. The other regions (`region_EMEA`, `region_APAC`, `region_LatAM`) also have positive coefficients, but with decreasing magnitude. This implies a hierarchy in terms of contribution to `total_revenue`, with `region_NorthAM` being the most influential.
  
2. **Retention Columns:**
   - `organic_retained_users` has a positive coefficient of \(0.7805\), which means for every additional user retained organically, the `total_revenue` increases by approximately \(0.78\). 
   - `retained_users` has a coefficient of \(0.1252\), indicating a smaller positive impact on `total_revenue` compared to organic retained users.
   
3. **Networks:**
   - The coefficient for `network_paymeent_PayPal` is \(0.0149\), implying a slight increase in `total_revenue` associated with this network.
   - `network_payment_MobilePay` has a negative coefficient, suggesting a decrease in `total_revenue` for this channel compared to the reference network.
<br>
   
4. **Spend:** A coefficient of \(0.0057\) indicates that for every unit increase in spend, there's a small positive effect on `total_revenue`.

5. **Cohort Sizes:** 
   - The negative coefficient for `cohort_size` (-0.0023) suggests a very slight decrease in `total_revenue` for every unit increase in the cohort size.
   - The negative coefficient for `organic_cohort_size` is larger in magnitude (-0.0215), implying a more noticeable negative effect on `total_revenue`.

6. **Channels:**
   - All channels (`iOS App`, `Website`, `Marketplace`) have negative coefficients, suggesting they negatively impact `total_revenue`. Among them, `Marketplace` has the largest negative coefficient, indicating it has the most significant negative impact on `total_revenue` compared to the reference channel.


### Results
- The model moderately fits the data, capturing around 33.75% of the variance in `total_revenue`.
- Regions play a significant role in predicting `total_revenue`, with `region_NorthAM` having the most substantial positive impact.
- Retention of organic users is more influential than general user retention in terms of increasing `total_revenue`.
- Among the channels, `Marketplace` has the highest negative impact on the revenue, suggesting potential areas for business improvement.
- While spend has a positive impact on `total_revenue`, the effect of cohort sizes is slightly negative, implying that other factors, such as user quality, might play a more crucial role than sheer numbers.


## 6) Further Analysis - Feature Engineering


To delve deep, further research analysis is identified for 'organic_revenue' feature and also extended analysis based on 'day_after_registration' features.

### 6.1) Analysis based on organic_revenue

**Performance Metrics:**
- **Mean Squared Error (MSE):** \(648.62\)
  - The MSE represents the average squared difference between the predicted and actual values. An MSE of \(648.62\) indicates the magnitude of the error made by the model in its predictions. A lower MSE is better as it indicates a tighter fit of the model to the data.
  
- **\( R^2 \) Score:** \(0.6573\)
  - The \( R^2 \) score measures the proportion of the variance in the dependent variable that is predictable from the independent variables. An \( R^2 \) score of \(0.6573\) suggests that the model explains about 65.73% of the variance in `total_organic_revenue`. This is a better score \( R^2 \) than the non-organic model, indicating that the model captures a significant portion of the underlying structure of the data.

**Feature Coefficients:**

1. **Regions:** 
   - `region_NorthAM` has the highest positive coefficient of \(5.44\), indicating that being in this region is associated with a significant increase in `total_organic_revenue`. The other regions also have positive coefficients but with decreasing magnitude, suggesting that `region_NorthAM` is the most influential among them.
  
2. **Retention and Cohort Sizes:**
   - `organic_retained_users` has a positive coefficient of \(0.598\), implying that for every additional user retained organically, there's a moderate increase in `total_organic_revenue`.
   - Both `cohort_size` and `organic_cohort_size` have negative coefficients, indicating that an increase in these variables might lead to a slight decrease in `total_organic_revenue`. This suggests that the quality of users (in terms of revenue generation) might be more crucial than sheer numbers.
   - `retained_users` has a negative coefficient of \(-0.03\), suggesting a small decrease in revenue for every unit increase in retained users. This might indicate that organic retention is more valuable than general retention.
   
3. **Networks:**
   - `network_name_MobilePay` has a positive coefficient, suggesting that this network is associated with an increase in `total_organic_revenue` compared to the reference network.
   - `network_name_PayPal`, on the other hand, has a negative coefficient, indicating a decrease in revenue when this network is the source.

4. **Spend:** A coefficient of \(0.000455\) indicates a very slight positive effect of spend on `total_organic_revenue`.

5. **Channels:**
   - All channels have negative coefficients, suggesting they reduce `total_organic_revenue` compared to the reference channel. Among them, `Marketplace` has the most significant negative impact, followed by `Website`, `iOS App`.
   
   
### 6.2) Analysis based on other feature "days_after_registration"

Results for the extended feature set:
                       Model  Mean Squared Error  R-squared
0          Linear Regression        12788.933178   0.337848
1      DecisionTreeRegressor         3615.488163   0.812807
2      RandomForestRegressor         1327.241857   0.931281
3  GradientBoostingRegressor         1286.143463   0.933409


## 7) Findings & Conclusion


### 7.1) Analysis Summary
- The model has a fairly good fit, capturing around 65.73% of the variance in `total_organic_revenue`.
- Regional factors play a significant role, with `region_NorthAM` being the most influential in predicting organic revenue.
- Organic retention has a positive influence on revenue, while general retention seems to have a slight negative impact. This might indicate the quality of organic users is superior in terms of revenue generation.
- The channel `Marketplace` has the most substantial negative impact on organic revenue, suggesting potential areas for business improvement or re-evaluation of the product or marketing strategies associated with this channel.


### 7.2) Conclusion
<br>- The score was pretty high for Random Forest, and GradientBoosting models.
<br>- But model was not able to predict revenue coherently was not able to capture any trend.
<br>- Growth percentages between cohorts was either to low or too high, not really caputring the real growth percentages for the channels.
<br>- Some numbers where negative, which is not possible in the real world. 
<br>- A detailed interpretation and evaluation of the best model can be analyzed together with suject matter experts for further improvements.

Thank You!